#!/usr/bin/env python3
"""
æŸ¥çœ‹æ‰€æœ‰è®°å½•çš„LLMäº¤äº’
æ˜¾ç¤ºå‘é€ç»™LLMçš„messageså’ŒLLMçš„responses
"""

import json
import os
from datetime import datetime

def view_all_llm_interactions():
    """æŸ¥çœ‹æ‰€æœ‰LLMäº¤äº’è®°å½•"""
    
    log_dir = "/tmp/openhands_logs"
    
    if not os.path.exists(log_dir):
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—ç›®å½•")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰ç±»å‹çš„æ—¥å¿—æ–‡ä»¶
    message_files = [f for f in os.listdir(log_dir) if f.startswith('real_messages_')]
    llm_files = [f for f in os.listdir(log_dir) if f.startswith('llm_interaction_')]
    
    print("ğŸ” OpenHands å®Œæ•´äº¤äº’è®°å½•")
    print("=" * 80)
    
    if message_files:
        print(f"\nğŸ“‹ ConversationMemory Messages ({len(message_files)} ä¸ªæ–‡ä»¶):")
        print("-" * 50)
        
        for msg_file in sorted(message_files):
            msg_path = os.path.join(log_dir, msg_file)
            try:
                with open(msg_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                print(f"ğŸ“„ {msg_file}")
                print(f"   æ—¶é—´: {data['timestamp']}")
                print(f"   æ¶ˆæ¯æ•°: {data['total_messages']}")
                print(f"   è§’è‰²åˆ†å¸ƒ: {data['role_distribution']}")
                
                # æ˜¾ç¤ºæ¶ˆæ¯æ‘˜è¦
                for i, msg in enumerate(data['messages'][:3], 1):  # åªæ˜¾ç¤ºå‰3æ¡
                    content = msg['content'][:60] + "..." if len(msg['content']) > 60 else msg['content']
                    print(f"   {i}. [{msg['role'].upper()}] {content}")
                
                if len(data['messages']) > 3:
                    print(f"   ... è¿˜æœ‰ {len(data['messages']) - 3} æ¡æ¶ˆæ¯")
                print()
                
            except Exception as e:
                print(f"âŒ è¯»å– {msg_file} å¤±è´¥: {e}")
    
    if llm_files:
        print(f"\nğŸ¤– LLMäº¤äº’è®°å½• ({len(llm_files)} ä¸ªæ–‡ä»¶):")
        print("-" * 50)
        
        for llm_file in sorted(llm_files):
            llm_path = os.path.join(log_dir, llm_file)
            try:
                with open(llm_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                print(f"ğŸ“„ {llm_file}")
                print(f"   æ¨¡å‹: {data['model']}")
                print(f"   è¯·æ±‚æ—¶é—´: {data['timestamp']}")
                print(f"   æ¶ˆæ¯æ•°: {data['total_messages']}")
                print(f"   è§’è‰²: {data['message_roles']}")
                
                if 'response' in data:
                    resp = data['response']
                    print(f"   å“åº”æ—¶é—´: {resp['response_timestamp']}")
                    print(f"   å»¶è¿Ÿ: {resp['latency_seconds']}ç§’")
                    
                    content = resp['response_content'][:80] + "..." if len(resp['response_content']) > 80 else resp['response_content']
                    print(f"   å“åº”å†…å®¹: {content}")
                    
                    if resp['tool_calls']:
                        print(f"   å·¥å…·è°ƒç”¨: {len(resp['tool_calls'])} ä¸ª")
                        for tc in resp['tool_calls'][:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                            print(f"     - {tc['function_name']}({tc['function_arguments'][:50]}...)")
                    
                    if 'usage' in resp['raw_response']:
                        usage = resp['raw_response']['usage']
                        print(f"   Tokenä½¿ç”¨: {usage['total_tokens']} (è¾“å…¥:{usage['prompt_tokens']}, è¾“å‡º:{usage['completion_tokens']})")
                
                print()
                
            except Exception as e:
                print(f"âŒ è¯»å– {llm_file} å¤±è´¥: {e}")
    
    if not message_files and not llm_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ—¥å¿—æ–‡ä»¶")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œä¸€äº›OpenHandsæ“ä½œæ¥ç”Ÿæˆæ—¥å¿—")

def show_latest_interaction_detail():
    """æ˜¾ç¤ºæœ€æ–°äº¤äº’çš„è¯¦ç»†ä¿¡æ¯"""
    
    log_dir = "/tmp/openhands_logs"
    llm_files = [f for f in os.listdir(log_dir) if f.startswith('llm_interaction_')]
    
    if not llm_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°LLMäº¤äº’è®°å½•")
        return
    
    latest_file = sorted(llm_files)[-1]
    latest_path = os.path.join(log_dir, latest_file)
    
    print(f"\nğŸ¯ æœ€æ–°LLMäº¤äº’è¯¦æƒ… ({latest_file}):")
    print("=" * 80)
    
    with open(latest_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print("ğŸ“¤ å‘é€ç»™LLMçš„Messages:")
    print("-" * 40)
    for i, msg in enumerate(data['messages'], 1):
        print(f"{i}. Role: {msg['role']}")
        print(f"   Content: {msg['content']}")
        if 'tool_call_id' in msg:
            print(f"   Tool Call ID: {msg['tool_call_id']}")
            print(f"   Tool Name: {msg.get('name', 'unknown')}")
        print()
    
    if 'response' in data:
        print("ğŸ“¥ LLMè¿”å›çš„Response:")
        print("-" * 40)
        resp = data['response']
        print(f"Response ID: {resp['response_id']}")
        print(f"Content: {resp['response_content']}")
        print(f"Latency: {resp['latency_seconds']}ç§’")
        
        if resp['tool_calls']:
            print(f"Tool Calls ({len(resp['tool_calls'])}):")
            for tc in resp['tool_calls']:
                print(f"  - {tc['function_name']}: {tc['function_arguments']}")
        
        print(f"\nRaw Response Structure:")
        print(json.dumps(resp['raw_response'], indent=2, ensure_ascii=False))

def show_summary():
    """æ˜¾ç¤ºäº¤äº’æ‘˜è¦"""
    
    log_dir = "/tmp/openhands_logs"
    
    if not os.path.exists(log_dir):
        return
    
    message_files = [f for f in os.listdir(log_dir) if f.startswith('real_messages_')]
    llm_files = [f for f in os.listdir(log_dir) if f.startswith('llm_interaction_')]
    
    print(f"\nğŸ“Š äº¤äº’æ‘˜è¦:")
    print("=" * 80)
    print(f"ConversationMemoryè®°å½•: {len(message_files)} ä¸ª")
    print(f"LLMäº¤äº’è®°å½•: {len(llm_files)} ä¸ª")
    
    if llm_files:
        total_tokens = 0
        total_latency = 0
        models_used = set()
        
        for llm_file in llm_files:
            llm_path = os.path.join(log_dir, llm_file)
            try:
                with open(llm_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                models_used.add(data['model'])
                
                if 'response' in data:
                    resp = data['response']
                    total_latency += resp.get('latency_seconds', 0)
                    
                    if 'usage' in resp['raw_response']:
                        usage = resp['raw_response']['usage']
                        total_tokens += usage.get('total_tokens', 0)
                        
            except:
                continue
        
        print(f"ä½¿ç”¨çš„æ¨¡å‹: {', '.join(models_used)}")
        print(f"æ€»Tokenä½¿ç”¨: {total_tokens}")
        print(f"å¹³å‡å»¶è¿Ÿ: {total_latency/len(llm_files):.2f}ç§’")
    
    print("\nğŸ’¡ è¿™äº›æ—¥å¿—è®°å½•äº†:")
    print("âœ… æ¯æ¬¡å‘é€ç»™LLMçš„å®Œæ•´messagesæ•°ç»„")
    print("âœ… LLMè¿”å›çš„å®Œæ•´response")
    print("âœ… è¯·æ±‚å‚æ•°ã€å»¶è¿Ÿã€tokenä½¿ç”¨ç­‰å…ƒæ•°æ®")
    print("âœ… ConversationMemoryå¤„ç†çš„äº‹ä»¶åˆ°æ¶ˆæ¯çš„è½¬æ¢")

if __name__ == "__main__":
    print("OpenHands LLMäº¤äº’æŸ¥çœ‹å™¨")
    print("è¿™é‡Œæ˜¾ç¤ºæ‰€æœ‰è®°å½•çš„LLMäº¤äº’æ•°æ®")
    
    view_all_llm_interactions()
    show_latest_interaction_detail()
    show_summary()
    
    print("\n" + "=" * 80)
    print("ğŸ¯ ç°åœ¨ä½ å¯ä»¥çœ‹åˆ°OpenHandsä¸LLMçš„å®Œæ•´äº¤äº’è¿‡ç¨‹ï¼")
    print("åŒ…æ‹¬å‘é€çš„messageså’Œæ¥æ”¶çš„responses")
    print("=" * 80)